set -x

# Add Tags to a volume
function add_tags {

     /opt/aws/bin/ec2-create-tags  -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY $1  --tag $MARKLOGIC_AUTO_SCALE_GROUP-$node_name-$2

}

function check_attached {
attached=`/opt/aws/bin/ec2-describe-volumes  -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY  | grep ATTACHMENT | grep $1 | grep $fdev | awk '{print $5}'`
}

# Attach a volume 
function attach {
     hex_representation=$( printf "%X" ${hex_val} )

     fdev=`printf "sd\x$hex_representation\n"`
        attach_fail=1
        while [ $attach_fail -eq 1 ]
        do

           latest_attach=1
           while [ $latest_attach -eq 1 ]
           do
             # Can be a delay from creation to availability to attach
             sleep 3
             /opt/aws/bin/ec2-attach-volume  $1 -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY  -i $2 -d /dev/$fdev > attach_response 2>&1
             latest_attach=`grep "is unavailable" attach_response  | wc -l`
           done
           # Now wait for it to actually attach
           # On Rare occasions AWS will return success from attach-volume without attaching
   
           check_attached $1
           while [ "$attached" != "attached" ] && [ "$attached" != "" ]
           do
              sleep 10
              check_attached $1
           done
           if  [ "$attached" = "attached" ]
           then
              attach_fail=0
           fi
        done
}

# Attach a volume 
function reattach {
        attach_fail=1
        while [ $attach_fail -eq 1 ]
        do
          # Can be a delay from creation to availability to attach
          sleep 3
          /opt/aws/bin/ec2-attach-volume  $1 -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY  -i $2 -d $fdev > attach_response 2>&1
          attach_fail=`grep "is unavailable" attach_response  | wc -l`
        done
        # Now wait for it to actually attach

        check_attached $1
        while [ "$attached" != "attached" ]
        do
           sleep 10
           check_attached $1
        done
}

# Create a volume
function make_volume {
     if [ $iops -eq 0 ]
     then
        this_volume=`/opt/aws/bin/ec2-create-volume  -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY  -s $1 -z $region -t standard  | awk '{print $2}'`
     else
        this_volume=`/opt/aws/bin/ec2-create-volume  -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY  -s $1 -z $region -t io1  -i $iops  | awk '{print $2}'`
     fi
     attach $this_volume $instance_id

     mkfs /dev/$fdev > $fdev.out 2>&1 &
     add_tags $this_volume $2
}



# Lock the meta data

function lock_meta {

   locked=1
   while [ $locked -eq 1 ]
   do

      # Note error from simpledb on stderr, redirect
      locked=`./simpledb put-conditional $1 meta meta_lock 0 meta_lock=$2 2>&1 | grep -c ERROR`
      if [ $locked -eq 1 ]
      then
         lock_response=`./simpledb get $1 meta meta_lock`
         lock_holder=`./simpledb get $1 meta meta_lock | awk ' BEGIN{FS="="}{print $2} '`
# Odd case instance is locked but get meta_lock returns 0
         if [ "$lock_holder" != "0" ] 
         then

         lock_holder_alive=`/opt/aws/bin/ec2-describe-instances -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY |  grep INSTANCE | awk '{print $2}' | grep $lock_holder | wc -l`
         if [ $lock_holder_alive -eq 1 ] && [  "$lock_holder" != "$instance_id" ]
         then
           sleep 10
         else
           # The lock holder is gone or is us from previous take over
           ./simpledb put-replace $1 meta meta_lock=$2
           locked=0
         fi
         else
           sleep 10
         fi
      fi
   done
}


# Get the launch config variables

/opt/aws/bin/ec2-metadata -d | awk '{for (i=2;i<=NF;i++){if ($i == "export"){printf "\n%s ",$i}else {printf "%s",$i}}}' > setup
source setup
export HOME=/root

# Check my credentials
if [ "$MARKLOGIC_AWS_ACCESS_KEY" == "none" ] || [ "$MARKLOGIC_AWS_SECRET_KEY" == "none" ] || [ "$MARKLOGIC_AWS_ACCESS_KEY" == "" ] || [ "$MARKLOGIC_AWS_SECRET_KEY" == "" ]
then
 # Without credentials we can do nothing
 exit
else
 # setup credentials for simple db
 printf "%s:%s" $MARKLOGIC_AWS_ACCESS_KEY $MARKLOGIC_AWS_SECRET_KEY > /etc/passwd-s3fs
 # setup the credentials for S3
 printf "access_key = %s\n" $MARKLOGIC_AWS_ACCESS_KEY > /root/.s3cfg
 printf "secret_key = %s\n" $MARKLOGIC_AWS_SECRET_KEY >> /root/.s3cfg
 cat s3cfg >> /root/.s3cfg

fi


# Extract data about the instance
instance_id=`/opt/aws/bin/ec2-metadata -i | awk '{print $2}'`
region=`/opt/aws/bin/ec2-metadata -z | awk '{print $2}'`
instance_name=`wget -q -O - http://169.254.169.254/latest/meta-data/public-hostname`
instance_type=`wget -q -O - http://169.254.169.254/latest/meta-data/instance-type`


# Determine my SDB cluster bucket and my ASG bucket
sdb_bucket_name=`echo $MARKLOGIC_AUTO_SCALE_GROUP | sed 's/--/__/' | sed 's/--/__/' | sed 's/-/_/'`
sdb_cluster_name=`echo $MARKLOGIC_AUTO_SCALE_GROUP | sed 's/--/__/' | sed 's/...$//'`

cluster_missing=`./simpledb get $sdb_cluster_name meta meta_lock 2>&1 | grep -c "The specified domain does not exist"`
if [ $cluster_missing -eq 1 ]
then
# If the user has not specified a cluster create one in SDB with sensible defaults
./simpledb create-domain $sdb_cluster_name
./simpledb put-replace $sdb_cluster_name meta meta_lock=instance_id
./simpledb put-replace $sdb_cluster_name meta join_lock=0
./simpledb put-replace $sdb_cluster_name meta master=none
./simpledb put-replace $sdb_cluster_name meta db_created=0
./simpledb put-replace $sdb_cluster_name meta meta_lock=0

fi


bucket_missing=`./simpledb get $sdb_bucket_name meta meta_lock 2>&1 | grep -c "The specified domain does not exist"`
if [ $bucket_missing -eq 1 ]
then
# If the user has not specified a bucket create one in SDB with sensible defaults
./simpledb create-domain $sdb_bucket_name
./simpledb put-replace $sdb_bucket_name meta meta_lock=instance_id
./simpledb put-replace $sdb_bucket_name meta storage=ebs
./simpledb put-replace $sdb_bucket_name meta backup=s3
./simpledb put-replace $sdb_bucket_name meta fastdir=none
./simpledb put-replace $sdb_bucket_name meta replica=none
./simpledb put-replace $sdb_bucket_name meta backup_iops=0
./simpledb put-replace $sdb_bucket_name meta replica_iops=0
./simpledb put-replace $sdb_bucket_name meta fastdir_iops=0
./simpledb put-replace $sdb_bucket_name meta storage_iops=1000
./simpledb put-replace $sdb_bucket_name meta opt_iops=0
./simpledb put-replace $sdb_bucket_name meta default_mount_points=2
./simpledb put-replace $sdb_bucket_name meta volume_size=500
./simpledb put-replace $sdb_bucket_name meta opt_volume_size=50
./simpledb put-replace $sdb_bucket_name meta backup_volume_size=1000
./simpledb put-replace $sdb_bucket_name meta fastdir_volume_size=0
./simpledb put-replace $sdb_bucket_name meta count=6
./simpledb put-replace $sdb_bucket_name meta rpm_uri=none
./simpledb put-replace $sdb_bucket_name meta meta_lock=0

fi


# Note need to lock SDB as someone may be updating the data
lock_meta $sdb_bucket_name $instance_id

# Extract our meta data from simple db
# Is the storage EBS or Ephemeral
storage=`./simpledb get $sdb_bucket_name meta storage | awk 'BEGIN{FS="="}{print $2}'`
backup=`./simpledb get $sdb_bucket_name meta backup | awk 'BEGIN{FS="="}{print $2}'`
fastdir=`./simpledb get $sdb_bucket_name meta fastdir | awk 'BEGIN{FS="="}{print $2}'`
replica=`./simpledb get $sdb_bucket_name meta replica | awk 'BEGIN{FS="="}{print $2}'`

# Are we using provisioned IOPs
backup_iops=`./simpledb get $sdb_bucket_name meta backup_iops | awk 'BEGIN{FS="="}{print $2}'`
replica_iops=`./simpledb get $sdb_bucket_name meta replica_iops | awk 'BEGIN{FS="="}{print $2}'`
storage_iops=`./simpledb get $sdb_bucket_name meta storage_iops | awk 'BEGIN{FS="="}{print $2}'`
fastdir_iops=`./simpledb get $sdb_bucket_name meta fastdir_iops | awk 'BEGIN{FS="="}{print $2}'`
opt_iops=`./simpledb get $sdb_bucket_name meta opt_iops | awk 'BEGIN{FS="="}{print $2}'`

# Whats the default number of mount points
default_mount_points=`./simpledb get $sdb_bucket_name meta default_mount_points | awk 'BEGIN{FS="="}{print $2}'`
if [ "default_$mount_points" == "" ]
then
    default_mount_points=2
fi

# Whats our /opt volume size
opt_volume_size=`./simpledb get $sdb_bucket_name meta opt_volume_size | awk 'BEGIN{FS="="}{print $2}'`
if [ "$opt_volume_size" == "" ]
then
    opt_volume_size=50
fi
# Whats our volume size
volume_size=`./simpledb get $sdb_bucket_name meta volume_size | awk 'BEGIN{FS="="}{print $2}'`
if [ "$volume_size" == "" ]
then
    volume_size=100
fi
# Whats our backup volume size
backup_volume_size=`./simpledb get $sdb_bucket_name meta backup_volume_size | awk 'BEGIN{FS="="}{print $2}'`
if [ "$backup_volume_size" == "" ]
then
    backup_volume_size=$volume_size
fi
# Whats our fastdir volume size
fastdir_volume_size=`./simpledb get $sdb_bucket_name meta fastdir_volume_size | awk 'BEGIN{FS="="}{print $2}'`
if [ "$fastdir_volume_size" == "" ]
then
    fastdir_volume_size=$volume_size
fi

# Where to load the ML binary from
download_location=`./simpledb get $sdb_bucket_name meta rpm_uri | awk 'BEGIN{FS="="}{print $2}'`


env

# Stop MarkLogic in case we need to attach

/etc/init.d/MarkLogic stop


# Algorithm
#                                Lock the ASG meta Lock
#
#                   Do I exist in the ASG List
#            Yes                                No
#       Reattach                       Any free slots in the ASG List
#                                Yes                    No
#                         Create Node             Any Dead nodes in the ASG List
#                         Create Volumes       No                        yes
#                         Attach             Start Standalone      Takeover Node
#                                                                  Attach volumes
#
#                              Unlock the ASG meta lock
#
#                              Lock Cluster Lock
#                              Check Cluster Master
#                         1. none?   Become Master - Database Created?  Create DB
#                         2. Dead?   Did I take over his node?  Yes I am Master, No wait for master
#                         3  Alive?  Nothing to do
#                              UnLock Cluster Lock
#              
#              Same node? Nothing to do
#              New node?  Join cluster
#              Takeover node?  Fix host, become master if I am master
  
                                  

# Need to lock the cluster bucket while we determine to become master
i_am_master=0

lock_meta $sdb_cluster_name $instance_id

master=`./simpledb get $sdb_cluster_name meta master | awk 'BEGIN{FS="="}{print $2}'`
if [ "$master" == "" ] || [ "$master" == "none" ]
then
  # Become the master
  ./simpledb put-replace $sdb_cluster_name meta master=$instance_name
  master_instance=$instance_name
  i_am_master=1
  master_alive=1
  db_created=`./simpledb get $sdb_cluster_name meta db_created | awk ' BEGIN{FS="="}{print $2} '`
  ./simpledb put-replace $sdb_cluster_name meta meta_lock=0
else
   master_alive=`/opt/aws/bin/ec2-describe-instances -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY |  grep INSTANCE | awk '{print $4}' | grep $master | wc -l`
   if [ $master_alive -eq 1 ]
   then
     master_instance=$master
     db_created=`./simpledb get $sdb_cluster_name meta db_created | awk ' BEGIN{FS="="}{print $2} '`
  ./simpledb put-replace $sdb_cluster_name meta meta_lock=0
   else 
      # Is the master in the node list
      printf "./simpledb select 'select ItemName()  from $sdb_bucket_name where ip = \"$master\"  ' \n" > get_node_name
      chmod 777 ./get_node_name
      master_node_name=`./get_node_name`
   fi
fi

# If the master is dead I will still hold the sdb_cluster_name lock




   new=0

   # Need to lock the simpledb bucket while we determine our node


   # Do I exist in my node list

   printf "./simpledb select 'select volume_name  from $sdb_bucket_name where ip = \"$instance_name\"  ' | awk ' BEGIN{FS=\"=\"} /volume/ {print \$2} '\n" > get_node_volume
   chmod 777 ./get_node_volume
   volume_name=`./get_node_volume`

# If 2
   if [ "$volume_name" != "" ]
   then

         # Came up as same node - nothing to do (handle joining) - simply reattach
         printf "./simpledb select 'select ItemName()  from $sdb_bucket_name where ip = \"$instance_name\"  ' \n" > get_node_name
         chmod 777 ./get_node_name
         node_name=`./get_node_name`

         mount_points=`./simpledb get $sdb_bucket_name $node_name mount_points | awk 'BEGIN{FS="="}{print $2}'`
         # Check everything is attached
         # /var/opt cannot be S3
           # Attach /var/opt
           volume_name=`./simpledb get $sdb_bucket_name $node_name volume_name | awk ' BEGIN{FS="="}{print $2} '`
           fdev=`./simpledb get $sdb_bucket_name $node_name mount_point | awk ' BEGIN{FS="="}{print $2} '`
           check_attached $volume_name
           if [ "$attached" != "attached" ]
           then
              reattach $volume_name $instance_id
           fi
           add_tags $volume_name "opt"
  
          # Attach backup
          
          if [ "$backup" == "ebs" ]
          then
             backup_volume_name=`./simpledb get $sdb_bucket_name $node_name backup_volume | awk ' BEGIN{FS="="}{print $2} '`
             fdev=`./simpledb get $sdb_bucket_name $node_name mount_point_backup | awk ' BEGIN{FS="="}{print $2} '`
             check_attached $backup_volume_name
             if [ "$attached" != "attached" ]
             then
                reattach $backup_volume_name $instance_id
             fi
             add_tags $backup_volume_name "backup"

          fi

 
          # Attach regular volumes 
          vol_count=1
          while [ $vol_count -le $mount_points ]
          do
             if [ "$storage" == "ebs" ]
             then
                mount_point_volume_name=`./simpledb get $sdb_bucket_name $node_name volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
                fdev=`./simpledb get $sdb_bucket_name $node_name mount_point_volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
                check_attached $mount_point_volume_name
                if [ "$attached" != "attached" ]
                then
                      reattach $mount_point_volume_name $instance_id
                fi 
                add_tags $mount_point_volume_name $vol_count
            fi
  
            vol_count=$(expr $vol_count + 1)
          done

          # Attach fastdir volumes
          
          vol_count=1
          while [ $vol_count -le $mount_points ]
          do
            if [ "$fastdir" == "ebs" ]
            then
               fastdir_volume_name=`./simpledb get $sdb_bucket_name $node_name fastdir_volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
               fdev=`./simpledb get $sdb_bucket_name $node_name fastdir_mount_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
               check_attached $fastdir_volume_name
               if [ "$attached" != "attached" ]
               then
                  reattach $fastdir_volume_name  $instance_id
               fi
               add_tags $fastdir_volume_name "fastdir_$vol_count"
            fi 
            vol_count=$(expr $vol_count + 1)
          done

          # Attach EBS volumes for replicas`
        
          vol_count=1
          while [ $vol_count -le $mount_points ]
          do
            if [ "$replica" == "ebs" ]
            then
             replica_volume_name=`./simpledb get $sdb_bucket_name $node_name replica_volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
             fdev=`./simpledb get $sdb_bucket_name $node_name replica_mount_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
             check_attached $replica_volume_name
             if [ "$attached" != "attached" ]
             then
                reattach $replica_volume_name  $instance_id
             fi
             add_tags $replica_volume_name "replica_$vol_count"

            fi
            vol_count=$(expr $vol_count + 1)
         done


         # Lock my node and unlock the meta lock
         ./simpledb put-replace $sdb_bucket_name $node_name node_lock=$instance_id
         ./simpledb put-replace $sdb_bucket_name meta meta_lock=0

   else
 


      num_nodes=`./simpledb get $sdb_bucket_name meta count | awk 'BEGIN{FS="="}{print $2}'`
   
      printf "./simpledb select 'select ItemName()  from $sdb_bucket_name where ItemName() like \"node\x25\" '  \n" > get_active_count
      chmod 777 ./get_active_count
      ./get_active_count > node_list
      active_nodes=`cat node_list | wc -l`
      k=1

       # Not a restart find a locked node where the instance is dead
       # Restarting the master is the priority

       # If 3a

       if [ $master_alive -eq 0 ] && [ "$master_node_name" != "" ]
       then

         # Become the master
         ./simpledb put-replace $sdb_cluster_name meta master=$instance_name
         master_instance=$instance_name
         i_am_master=1
         db_created=`./simpledb get $sdb_cluster_name meta db_created | awk ' BEGIN{FS="="}{print $2} '`
         ./simpledb put-replace $sdb_cluster_name meta meta_lock=0

         # lock our node and unlock the meta
          node_name=`echo $master_node_name`
          k=`echo $master_node_name | awk '{print substr($1,5)}'`
       else

        # If 4a
        if [ $active_nodes -ne 0 ]
        then

        # Not recovering the master look for other dead nodes

        lock_holder_alive=1
        lock_holder_az=`echo none`
        while [ $lock_holder_alive -eq 1 ] && [ $k -le $active_nodes ]
        do
             lock_holder=`./simpledb get $sdb_bucket_name node$k node_lock | awk ' BEGIN{FS="="}{print $2} '`
             lock_holder_az=`./simpledb get $sdb_bucket_name node$k az | awk ' BEGIN{FS="="}{print $2} '`
             lock_holder_alive=`/opt/aws/bin/ec2-describe-instances -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY |  grep INSTANCE | grep running | grep $lock_holder | wc -l`
             if [ $lock_holder_alive -eq 1 ]
             then 
               k=$(expr $k + 1)
             fi
        done
        # Fi 4a
        fi

        # Fi 3a
        fi

        # If 3b
        if [ $k -le $active_nodes ]
        then
          # Save the old IP name so we can replace it in ML cluster
          node_ip=`./simpledb get $sdb_bucket_name node$k ip | awk ' BEGIN{FS="="}{print $2} '`

          # Found a candidate to take over
          node_name=`echo node$k`

          # lock our node and unlock the meta
          new=2
          ./simpledb put-replace $sdb_bucket_name $node_name node_lock=$instance_id
          ./simpledb put-replace $sdb_bucket_name meta meta_lock=0
      mount_points=`./simpledb get $sdb_bucket_name node$k mount_points | awk ' BEGIN{FS="="}{print $2} '`
  
      hex_val=104
      # /var/opt cannot be S3
          # Attach /var/opt
          volume_name=`./simpledb get $sdb_bucket_name node$k volume_name | awk ' BEGIN{FS="="}{print $2} '`
          attach $volume_name $instance_id
          add_tags $volume_name "opt"
          hex_val=$(expr $hex_val + 1)
  
          # Attach backup
          
          if [ "$backup" == "ebs" ]
          then
             backup_volume_name=`./simpledb get $sdb_bucket_name $node_name backup_volume | awk ' BEGIN{FS="="}{print $2} '`
             attach $backup_volume_name $instance_id
  
            ./simpledb put-replace $sdb_bucket_name $node_name backup_volume=$backup_volume_name mount_point_backup=/dev/$fdev
            hex_val=$(expr $hex_val + 1)
            add_tags $backup_volume_name "backup"

          fi

 
          # Attach regular volumes 
          vol_count=1
          while [ $vol_count -le $mount_points ]
          do
             if [ "$storage" == "ebs" ]
             then
                mount_point_volume_name=`./simpledb get $sdb_bucket_name $node_name volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
                attach $mount_point_volume_name $instance_id
  
               ./simpledb put-replace $sdb_bucket_name $node_name mount_point_volume_$vol_count=/dev/$fdev
               add_tags $mount_point_volume_name $vol_count
               hex_val=$(expr $hex_val + 1)
            fi
  
            vol_count=$(expr $vol_count + 1)
          done

          # Attach fastdir volumes
          
          vol_count=1
          while [ $vol_count -le $mount_points ]
          do
            if [ "$fastdir" == "ebs" ]
            then
               fastdir_volume_name=`./simpledb get $sdb_bucket_name $node_name fastdir_volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
               attach $fastdir_volume_name  $instance_id
               add_tags $fastdir_volume_name "fastdir_$vol_count"
               ./simpledb put-replace $sdb_bucket_name $node_name fastdir_volume_$vol_count=$fastdir_volume_name fastdir_mount_$vol_count=/dev/$fdev
               hex_val=$(expr $hex_val + 1)
            fi 
            vol_count=$(expr $vol_count + 1)
          done

          # Attach EBS volumes for replicas`
        
          vol_count=1
          while [ $vol_count -le $mount_points ]
          do
            if [ "$replica" == "ebs" ]
            then
             replica_volume_name=`./simpledb get $sdb_bucket_name $node_name replica_volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
             attach $replica_volume_name  $instance_id
             add_tags $replica_volume_name "replica_$vol_count"
             ./simpledb put-replace $sdb_bucket_name $node_name replica_volume_$vol_count=$replica_volume_name replica_mount_$vol_count=/dev/$fdev
             hex_val=$(expr $hex_val + 1)

            fi
           vol_count=$(expr $vol_count + 1)
         done

        else
          # No nodes found for takeover k should point to first free slot or end
          # If 4b
          if [ $k -le $num_nodes ]
          then
            # New node in a spare slot
            node_name=`echo node$k`
            new=1
            # Lock my node and unlock the meta lock
            ./simpledb put-replace $sdb_bucket_name $node_name node_lock=$instance_id
            ./simpledb put-replace $sdb_bucket_name meta meta_lock=0

            hex_val=104
            iops=$opt_iops
            make_volume $opt_volume_size "opt"
            volume_name=$this_volume
            ./simpledb put $sdb_bucket_name $node_name volume_name=$volume_name mount_point=/dev/$fdev


            mount_points=`./simpledb get $sdb_bucket_name $node_name mount_points | awk 'BEGIN{FS="="}{print $2}'`

            if [ "$mount_points" == "" ]
            then
               mount_points=$default_mount_points
            fi

            # Create an EBS volume for backup
            hex_val=105
        
            if [ "$backup" == "ebs" ]
            then
               iops=$backup_iops
               make_volume $backup_volume_size "backup"
               backup_volume_name=$this_volume
               ./simpledb put $sdb_bucket_name $node_name backup_volume=$backup_volume_name mount_point_backup=/dev/$fdev
            else
               if [ "$backup" == "s3" ]
               then
                   backup_bucket_name=`echo marklogic-$sdb_cluster_name-$sdb_bucket_name-backup`
                   backup_exists=`/home/ec2-user/s3cmd-1.1.0-beta3/s3cmd ls | grep $backup_bucket_name | wc -l`
                   if [ $backup_exists -eq 0 ]
                   then
                     /home/ec2-user/s3cmd-1.1.0-beta3/s3cmd mb s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-backup
                   fi
                   ./simpledb put $sdb_bucket_name $node_name backup_volume=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-backup mount_point_backup=none
               fi

            fi

             # Create an EBS volume for each mount_point
             hex_val=106
             vol_count=1
             while [ $vol_count -le $mount_points ]
             do
                if [ "$storage" == "ebs" ]
                then
                  iops=$storage_iops
                  make_volume $volume_size "$vol_count"
                  mount_point_volume_name=$this_volume
                  ./simpledb put $sdb_bucket_name $node_name volume_$vol_count=$mount_point_volume_name mount_point_volume_$vol_count=/dev/$fdev
                else
                   if [ "$storage" == "s3" ]
                   then
                     data_bucket_name=`echo marklogic-$sdb_cluster_name-$sdb_bucket_name-data`
                     data_exists=`/home/ec2-user/s3cmd-1.1.0-beta3/s3cmd ls | grep $data_bucket_name | wc -l`
                     if [ $data_exists -eq 0 ]
                     then
                       /home/ec2-user/s3cmd-1.1.0-beta3/s3cmd mb s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-data
                     fi
                      ./simpledb put $sdb_bucket_name $node_name volume_$vol_count=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-data/$sdb_bucket_name-$node_name-$vol_count mount_point_volume_$vol_count=none
                   fi
                fi
           
                vol_count=$(expr $vol_count + 1)
                hex_val=$(expr $hex_val + 1)
             done
            # Create an EBS volume for fastdir
        
            if [ "$fastdir" == "ebs" ]
            then
                vol_count=1
                while [ $vol_count -le $mount_points ]
                do
                  iops=$fastdir_iops
                  make_volume $fastdir_volume_size "fastdir-$vol_count"
                  fastdir_volume_name=$this_volume
                  ./simpledb put $sdb_bucket_name $node_name fastdir_volume_$vol_count=$fastdir_volume_name fastdir_mount_$vol_count=/dev/$fdev
                   vol_count=$(expr $vol_count + 1)
                   hex_val=$(expr $hex_val + 1)
                done
             fi
            # Create an EBS volume for replicas`
        
            vol_count=1
            while [ $vol_count -le $mount_points ]
            do
              if [ "$replica" == "ebs" ]
              then
                 iops=$replica_iops
                 make_volume $volume_size "replica-$vol_count"
                 replica_volume_name=$this_volume
                 ./simpledb put $sdb_bucket_name $node_name replica_volume_$vol_count=$replica_volume_name replica_mount_$vol_count=/dev/$fdev
              else
                 if [ "$replica" == "s3" ]
                 then
                   replica_bucket_name=`echo marklogic-$sdb_cluster_name-$sdb_bucket_name-replica`
                   replica_exists=`/home/ec2-user/s3cmd-1.1.0-beta3/s3cmd ls | grep $replica_bucket_name | wc -l`
                   if [ $replica_exists -eq 0 ]
                   then
                     /home/ec2-user/s3cmd-1.1.0-beta3/s3cmd mb s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-replica
                   fi
                   ./simpledb put $sdb_bucket_name $node_name replica_volume_$vol_count=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-replica/$sdb_bucket_name-$node_name-replica-$vol_count replica_mount_$vol_count=none
                 fi
              fi
              vol_count=$(expr $vol_count + 1)
              hex_val=$(expr $hex_val + 1)
            done
               
         else
             # No free slots exit
             # Need to check here do I hold the cluster lock and release if necessary
             lock_holder=`./simpledb get $sdb_cluster_name meta meta_lock | awk ' BEGIN{FS="="}{print $2} '`
             if [ "$lock_holder" == "$instance_id" ]
             then
                    ./simpledb put-replace $sdb_cluster_name meta meta_lock=0
             fi
             lock_holder=`./simpledb get $sdb_bucket_name meta meta_lock | awk ' BEGIN{FS="="}{print $2} '`
             if [ "$lock_holder" == "$instance_id" ]
             then
                    ./simpledb put-replace $sdb_bucket_name meta meta_lock=0
             fi
             exit

         # Fi 4b
         fi

    # Fi 3b
    fi
   
   # Fi 2
   fi


# Fix up the simpledb entry for my node

if [ $new -eq 1 ]
then
    ./simpledb put $sdb_bucket_name $node_name ip=$instance_name az=$region instance=$instance_id mount_points=$mount_points instance_type=$instance_type
else
    ./simpledb put-replace $sdb_bucket_name  $node_name volume=$volume_name ip=$instance_name az=$region instance=$instance_id mount_points=$mount_points instance_type=$instance_type
fi


# Need to check here do I hold the cluster or bucket lock and release if necessary
# Should only hold the node lock at this point
lock_holder=`./simpledb get $sdb_cluster_name meta meta_lock | awk ' BEGIN{FS="="}{print $2} '`
if [ "$lock_holder" == "$instance_id" ]
then
   ./simpledb put-replace $sdb_cluster_name meta meta_lock=0
fi

lock_holder=`./simpledb get $sdb_bucket_name meta meta_lock | awk ' BEGIN{FS="="}{print $2} '`
if [ "$lock_holder" == "$instance_id" ]
then
   ./simpledb put-replace $sdb_bucket_name meta meta_lock=0
fi

if [ $new -gt 0 ]
then

# This is a new instance, check if we need to download ML, do this in paralell with any mkfs going on

this_rpm=MarkLogic-7.0-ea1_20130315.x86_64.rpm
   
# Uncomment this code to auto download a new binary
#   if [ "$download_location" == "none" ]
#   then
#      this_rpm=MarkLogic-7.0-ea1_20130315.x86_64.rpm
#   else
#
#      this_rpm=`basename $download_location`
#      if [ ! -f $this_rpm ]
#      then
#         /usr/bin/wget --user user  --password password $download_location
#      fi
#
#   fi
fi

# We kicked off the mkfs operation on all the volumes need to wait for completion
if [ $new -eq 1 ]
then
   wait
fi


# Mount any mount points that need it
opt_mounted=`df -k | grep "\/var\/opt\$" | wc -l`
if [ $opt_mounted -eq 0 ]
then
   mount_point=`./simpledb get $sdb_bucket_name $node_name mount_point | awk ' BEGIN{FS="="}{print $2} '`
   if [ $new -eq 1 ]
   then
      fdev=`basename $mount_point`
      mkfs_failed=`cat $fdev.out | grep "The device apparently does not exist" | wc -l`
      if [ $mkfs_failed -eq 1 ]
      then 
        # Odd case - EBS vol not fully attached when mkfs fired, retry
        mkfs $mount_point > $fdev.out
      fi
   fi
   mount $mount_point /var/opt
fi


if [ "$backup" == "ebs" ]
then
   back_mounted=`df -k | grep "\/var\/opt\/backup\$" | wc -l`
   if [ $back_mounted -eq 0 ]
   then

      mount_point=`./simpledb get $sdb_bucket_name $node_name mount_point_backup | awk ' BEGIN{FS="="}{print $2} '`
      if [ ! -d "/var/opt/backup" ]
      then
        mkdir /var/opt/backup
      fi
      chmod 777  /var/opt/backup
      if [ $new -eq 1 ]
      then
         fdev=`basename $mount_point`
         mkfs_failed=`cat $fdev.out | grep "The device apparently does not exist" | wc -l`
         if [ $mkfs_failed -eq 1 ]
         then 
           # Odd case - EBS vol not fully attached when mkfs fired, retry
           mkfs $mount_point > $fdev.out
         fi
      fi
      mount $mount_point /var/opt/backup
    fi
    chmod 777 /var/opt/backup 
fi

# If still dont have a backup create it
if [ ! -d "/var/opt/backup" ]
then
   mkdir /var/opt/backup
   chmod 777 /var/opt/backup
fi

if [ ! -d "/var/opt/mldata" ]
then
   mkdir /var/opt/mldata
   chmod 777 /var/opt/mldata
fi


vol_count=1
while [ $vol_count -le $mount_points ]
do
  if [ "$fastdir" == "ebs" ]
  then
   fast_mounted=`df -k | grep "\/var\/opt\/mldata\/$sdb_bucket_name-$node_name-fastdir-$vol_count" | wc -l`
   if [ $fast_mounted -eq 0 ]
   then

      mount_point=`./simpledb get $sdb_bucket_name $node_name fastdir_mount_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
      if [ ! -d "/var/opt/mldata/$sdb_bucket_name-$node_name-fastdir-$vol_count" ]
      then
        mkdir /var/opt/mldata/$sdb_bucket_name-$node_name-fastdir-$vol_count
        chmod 777  /var/opt/mldata/$sdb_bucket_name-$node_name-fastdir-$vol_count
      fi
      if [ $new -eq 1 ]
      then
         fdev=`basename $mount_point`
         mkfs_failed=`cat $fdev.out | grep "The device apparently does not exist" | wc -l`
         if [ $mkfs_failed -eq 1 ]
         then 
           # Odd case - EBS vol not fully attached when mkfs fired, retry
           mkfs $mount_point > $fdev.out
         fi
      fi
      mount $mount_point /var/opt/mldata/$sdb_bucket_name-$node_name-fastdir-$vol_count
    fi
    chmod 777 /var/opt/mldata/$sdb_bucket_name-$node_name-fastdir-$vol_count 
   fi
   vol_count=$(expr $vol_count + 1)
 done
vol_count=1
while [ $vol_count -le $mount_points ]
do
  if [ "$replica" == "ebs" ]
  then
   fast_mounted=`df -k | grep "\/var\/opt\/mldata\/$sdb_bucket_name-$node_name-replica-$vol_count" | wc -l`
   if [ $fast_mounted -eq 0 ]
   then

      mount_point=`./simpledb get $sdb_bucket_name $node_name replica_mount_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
      if [ ! -d "/var/opt/mldata/$sdb_bucket_name-$node_name-replica-$vol_count" ]
      then
        mkdir /var/opt/mldata/$sdb_bucket_name-$node_name-replica-$vol_count
      fi
      chmod 777  /var/opt/mldata/$sdb_bucket_name-$node_name-replica-$vol_count
      if [ $new -eq 1 ]
      then
         fdev=`basename $mount_point`
         mkfs_failed=`cat $fdev.out | grep "The device apparently does not exist" | wc -l`
         if [ $mkfs_failed -eq 1 ]
         then 
           # Odd case - EBS vol not fully attached when mkfs fired, retry
           mkfs $mount_point > $fdev.out
         fi
      fi
      mount $mount_point /var/opt/mldata/$sdb_bucket_name-$node_name-replica-$vol_count
    fi
    chmod 777 /var/opt/mldata/$sdb_bucket_name-$node_name-replica-$vol_count 
   fi
   vol_count=$(expr $vol_count + 1)
 done

 # Mount the ebs volumes
 vol_count=1
 if [ "$storage" == "ebs" ]
 then
   while [ $vol_count -le $mount_points ]
   do
     data_mounted=`df -k | grep "\/var\/opt\/mldata\/$sdb_bucket_name-$node_name-$vol_count\$" | wc -l`
     if [ $data_mounted -eq 0 ]
     then
        mount_point=`./simpledb get $sdb_bucket_name $node_name mount_point_volume_$vol_count | awk ' BEGIN{FS="="}{print $2} '`
        if [ ! -d "/var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count" ]
        then
           mkdir /var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count
        fi 
        chmod 777  /var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count
      if [ $new -eq 1 ]
      then
         fdev=`basename $mount_point`
         mkfs_failed=`cat $fdev.out | grep "The device apparently does not exist" | wc -l`
         if [ $mkfs_failed -eq 1 ]
         then 
           # Odd case - EBS vol not fully attached when mkfs fired, retry
           mkfs $mount_point > $fdev.out
         fi
      fi
        mount $mount_point /var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count
        if [ ! -d "/var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count/zips" ]
        then
           mkdir /var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count/zips
        fi 
        chmod 777  /var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count/zips
        cp copy_s3_forests /var/opt/mldata/$sdb_bucket_name-$node_name-$vol_count/zips
     fi
     vol_count=$(expr $vol_count + 1)
   done
 fi

chmod 777  /var/opt/mldata/*

if [ $new -ne 1 ]
then

   current_version=`grep accepted-version /var/opt/MarkLogic/server.xml | awk 'BEGIN{FS=">"}{split ($2,ver,"<");print ver[1]}'`
   new_version=`echo $this_rpm | awk -v cversion="$current_version" '{if (match($1,cversion)){printf "0"}else{printf "1"}}'`
else
   new_version=1
fi

if [ $new_version -eq 1 ]
then
   rpm -e MarkLogic

   rpm -i $this_rpm

   sed -i 's/MARKLOGIC_EC2_HOST=1/MARKLOGIC_EC2_HOST=0/' /etc/sysconfig/MarkLogic

   cp join-cluster.xqy qa-restart.xqy transfer-cluster-config.xqy /opt/MarkLogic/Admin
   cp xqy/bookmark.xqy xqy/delete.xqy xqy/search-debug.xqy xqy/search.xqy  xqy/update.xqy xqy/verify.xqy xqy/view.xqy /var/opt/xqy

   cp get_db_id.xqy stats.xqy http-server-status.xqy get-hosts.xqy attach_replica.xqy detach_replica.xqy create_markmail_forests.xqy create_forests.xqy create_forests_with_fastdir.xqy create_s3_forests.xqy create_s3_forests_with_fastdir.xqy create_s3_replica_forests.xqy create_s3_replica_forests_with_fastdir.xqy create_replica_forests.xqy create_replica_forests_with_fastdir.xqy create_markmail_database.xqy attach_markmail_forests.xqy create_markmail_appserver.xqy create_httpserver.xqy create_role.xqy rewrite-hostname.xqy rewrite-assignments.xqy  /opt/MarkLogic/Admin

fi


   # Should be ok to start MarkLogic
   /etc/init.d/MarkLogic start
   # Have seen cases where startup takes some time
   sleep 10 

if [ $new_version -eq 1 ] && [ $new -ne 1 ]
then
  # We upgraded the version need to accept the agreement
  curl --digest -u admin:hap00p http://localhost:8001/agree-go.xqy?accepted-agreement=development
  curl --digest -u admin:hap00p http://localhost:8001/qa-restart.xqy
  sleep 10 
fi



# Replace the name

if [ $new -eq 2 ]
then

printf "./simpledb select 'select ip  from $sdb_bucket_name where master = \"true\"  ' | awk ' BEGIN{FS=\"=\"} /ip/ {print \$2} ' \n" > get_master_ip
chmod 777 ./get_master_ip
master=`./get_master_ip`

curl --digest -u admin:hap00p http://$master_instance:8001/rewrite-hostname.xqy?oldhost=$node_ip\&newhost=$instance_name
sleep 10
# Need to restart this node so that any Appservers are listening with the new IP address
curl --digest -u admin:hap00p http://localhost:8001/qa-restart.xqy
sleep 30

fi




if [ $new -eq 1 ] || [ $db_created -eq 0 ]
   then
      echo $instance_name > hosts.txt
      python clusterInit.py -n hosts.txt -u ec2-user -l license.txt  > init_ml
      chmod 777 init_ml
      ./init_ml


      if [ $i_am_master -eq 1 ] && [ $db_created -eq 0 ]      
      then
         python clusterBuild.py -n hosts.txt -u ec2-user -l license.txt  > init_ml
         chmod 777 init_ml
         sleep 10
         ./init_ml 

         python clusterEnd.py -n hosts.txt -u ec2-user -l license.txt  > init_ml
         chmod 777 init_ml
         ./init_ml
         sleep 30
         # Encode our AWS credentials and put them into the DB.  Need this if creating s3 forests
         encoded_aws_access_key=$(php -r "echo urlencode(\"$MARKLOGIC_AWS_ACCESS_KEY\");")
         encoded_aws_secret_key=$(php -r "echo urlencode(\"$MARKLOGIC_AWS_SECRET_KEY\");")
         curl  --digest -u admin:hap00p http://$master_instance:8001/credentials-admin-go.xqy?/sec:credentials/sec:aws-access-key=$encoded_aws_access_key\&/sec:credentials/sec:aws-secret-key=$encoded_aws_secret_key
         # Need to restart this node so the credentials are used
         curl --digest -u admin:hap00p http://localhost:8001/qa-restart.xqy
         sleep 30

         curl --digest -u admin:hap00p http://localhost:8001/create_markmail_database.xqy

        if [ "$storage" == "ebs" ]
        then
 
          if [ "$fastdir" == "ebs" ]
          then
           curl --digest -u admin:hap00p http://localhost:8001/create_forests_with_fastdir.xqy?datadir=/var/opt/mldata\&fastdir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
          else
           curl --digest -u admin:hap00p http://localhost:8001/create_markmail_forests.xqy?datadir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
          fi
        else
          if [ "$storage" == "s3" ]
          then
             if [ "$fastdir" == "ebs" ]
             then
              curl --digest -u admin:hap00p http://localhost:8001/create_s3_forests_with_fastdir.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-data\&fastdir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
             else
              curl --digest -u admin:hap00p http://localhost:8001/create_s3_forests.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-data\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
             fi
          fi
        fi
 
        if [ "$replica" == "ebs" ]
        then 
           curl --digest -u admin:hap00p http://localhost:8001/create_replica_forests.xqy?datadir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
        else
          if [ "$replica" == "s3" ]
          then
             if [ "$fastdir" == "ebs" ]
             then
              curl --digest -u admin:hap00p http://localhost:8001/create_s3_replica_forests_with_fastdir.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-replica\&fastdir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
             else
              curl --digest -u admin:hap00p http://localhost:8001/create_s3_replica_forests.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-replica\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
             fi
          fi
        fi
           curl --digest -u admin:hap00p http://localhost:8001/attach_markmail_forests.xqy?fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
         sleep 10
         date
         curl --digest -u admin:hap00p http://localhost:8001/create_role.xqy
         sleep 10
         curl --digest -u admin:hap00p http://localhost:8001/create_markmail_appserver.xqy
# Turn on performance metering
         curl --digest -u admin:hap00p http://localhost:8001/set_metering_on.xqy

#         dbid=`curl --digest -u admin:hap00p 'http://localhost:8001/get_db_id.xqy?dbname=MarkMail'`
#         curl --digest -u admin:hap00p http://localhost:8001/database-backup-go.xqy?dir=/var/opt/backup\&database=$dbid
# We are open for business
         ./simpledb put-replace $sdb_cluster_name meta db_created=1

      else

        while [ $db_created -eq 0 ]
        do
          db_created=`./simpledb get $sdb_cluster_name meta db_created | awk ' BEGIN{FS="="}{print $2} '`
          sleep 10
        done

        locked=1
        while [ $locked -eq 1 ]
        do

           # Note error from simpledb on stderr, redirect
           locked=`./simpledb put-conditional $sdb_cluster_name meta join_lock 0 join_lock=$instance_id 2>&1 | grep -c ERROR`
           if [ $locked -eq 1 ]
           then
           # Check to see if the lock holder still exists

              lock_holder=`./simpledb get $sdb_cluster_name meta join_lock | awk ' BEGIN{FS="="}{print $2} '`
              lock_holder_alive=`/opt/aws/bin/ec2-describe-instances -O $MARKLOGIC_AWS_ACCESS_KEY  -W $MARKLOGIC_AWS_SECRET_KEY |  grep INSTANCE | awk '{print $2}' | grep $lock_holder | wc -l`
              if [ $lock_holder_alive -eq 1 ]
              then
                sleep 10
              else
                # The lock holder is gone take over
                ./simpledb put-replace $sdb_cluster_name meta join_lock=$instance_id
                locked=0
              fi
           fi

           done
        python clusterJoin.py -n hosts.txt -u ec2-user -l license.txt -c $master_instance > init_ml
         chmod 777 init_ml
         ./init_ml 

        sleep 30
        if [ "$storage" == "ebs" ]
        then
 
          if [ "$fastdir" == "ebs" ]
          then
           curl --digest -u admin:hap00p http://$master_instance:8001/create_forests_with_fastdir.xqy?datadir=/var/opt/mldata\&fastdir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
          else
           curl --digest -u admin:hap00p http://$master_instance:8001/create_markmail_forests.xqy?datadir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
          fi
        else
          if [ "$storage" == "s3" ]
          then
             if [ "$fastdir" == "ebs" ]
             then
              curl --digest -u admin:hap00p http://$master_instance:8001/create_s3_forests_with_fastdir.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-data\&fastdir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
             else
              curl --digest -u admin:hap00p http://$master_instance:8001/create_s3_forests.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-data\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
             fi
          fi
        fi
 
#        if [ "$replica" == "ebs" ]
#        then 
#          if [ "$fastdir" == "ebs" ]
#          then
#           curl --digest -u admin:hap00p http://$master_instance:8001/create_replica_forests_with_fastdir.xqy?datadir=/var/opt/mldata\&fastdir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
#          else
#           curl --digest -u admin:hap00p http://$master_instance:8001/create_replica_forests.xqy?datadir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
#          fi
##        else
#          if [ "$replica" == "s3" ]
#          then
#             if [ "$fastdir" == "ebs" ]
#             then
#              curl --digest -u admin:hap00p http://$master_instance:8001/create_s3_replica_forests_with_fastdir.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-replica\&fastdir=/var/opt/mldata\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
#             else
#              curl --digest -u admin:hap00p http://$master_instance:8001/create_s3_replica_forests.xqy?datadir=s3://marklogic-$sdb_cluster_name-$sdb_bucket_name-replica\&fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
#             fi
#          fi
#        fi
        sleep 10
        curl --digest -u admin:hap00p http://$master_instance:8001/attach_markmail_forests.xqy?fcount=$mount_points\&host=$instance_name\&node=$node_name\&cluster=$sdb_bucket_name
        sleep 10


        python clusterEnd.py -n hosts.txt -u ec2-user -l license.txt  > init_ml
        chmod 777 init_ml
        ./init_ml
        # Release the lock
        ./simpledb put-replace $sdb_cluster_name meta join_lock=0
     fi



fi


#old code

disable=1
if [ $disable -eq 0 ]
then
 umount /media/ephemeral0 
 mkdir /var/opt
 mkdir /space2
 chmod 777 /var/opt 
 chmod 777 /space2


 if [ "$storage" == "ephemeral" ]
 then
    mount /dev/xvdb /var/opt
    dd if=/dev/zero of=/var/opt/swapfile1 bs=1024 count=8388608
    mkswap /var/opt/swapfile1
    swapon /var/opt/swapfile1
 else
    mount /dev/xvdb /space2 
    dd if=/dev/zero of=/space2/swapfile1 bs=1024 count=8388608
    mkswap /space2/swapfile1
    swapon /space2/swapfile1
 fi 

fi


disable=1
if [ $disable -eq 0 ]
then

# Just reattach plumbing
chmod 777 /var/opt 
chmod 777 /space2
mount /dev/xvdb /space2 
swapon /space2/swapfile1

fi

