s3_bucket_name=$1
max_parallel=$2 

rm split_list
rm copied_over

file_list=`/home/ec2-user/s3cmd-1.1.0-beta3/s3cmd ls s3://$s3_bucket_name | awk '{print $4}'`
for i in $file_list
do
outstanding_copies=`ps -ef | grep s3cmd | grep -v grep | wc -l`
while [ $outstanding_copies -ge $max_parallel ]
do
    sleep 20
    outstanding_copies=`ps -ef | grep s3cmd | grep -v grep | wc -l`
done

/home/ec2-user/s3cmd-1.1.0-beta3/s3cmd get $i &
fname=`basename $i`
a_zip=`echo $fname | awk '/\.zip/ {printf "1"} !/\.zip/ {printf "0"}'`

if [ $a_zip -eq 1 ]
then
echo $fname >> copied_over
fi

first_split=`echo $i | awk '/\.001/ {printf "1"} !/\.001/ {printf "0"}'`  
if [ $first_split -eq 1 ]
then  
#  directory1=`echo $fname | awk 'BEGIN{FS="-"}{printf "%s-%s",$1,$2}'`
#  directory2=`echo $fname | awk 'BEGIN{FS="-"}{printf "%s",$3}'`
#  echo "$fname $directory1/$directory2" >> split_list
  echo "lxsplit -j $fname " >> split_list
fi


done
